% !TEX root =  ../extended abstract.tex 
\section{Personalized Schedules for Repeat Biopsies}
\label{sec : pers_sched_approaches}
We intend to use the JM fitted to $\mathcal{D}_n$, to create personalized schedules of biopsies. Let us assume that a schedule is to be created for a new patient $j$, who is not present in $\mathcal{D}_n$. Let $t$ be the time of his latest biopsy, and $\mathcal{Y}_{j1}(s), \mathcal{Y}_{j2}(s)$ denote his historical PSA and DRE measurements, respectively, up to time $s$. The goal is to find the optimal time $u > \mbox{max}(t,s)$ of the next biopsy. To this end, first the observed patient data is used to create a posterior predictive distribution $g(T^*_j)$ of the GR time:
\begin{equation*}
\label{eq : dyn_dist_fail_time}
\begin{split}
g(T^*_j) &= p\big\{T^*_j \mid T^*_j > t, \mathcal{Y}_j(s), \mathcal{D}_n\big\}\\
&= \int \int p\big(T^*_j \mid T^*_j > t, \bmath{b}_j, \bmath{\theta}\big)p\big\{\bmath{b}_j \mid T^*_j>t, \mathcal{Y}_j(s), \bmath{\theta}\big\}p\big(\bmath{\theta} \mid \mathcal{D}_n\big) \rmn{d} \bmath{b}_j \rmn{d} \bmath{\theta}.
\end{split}
\end{equation*}
The distribution $g(T^*_j)$ depends on $\mathcal{Y}_{j1}(s), \mathcal{Y}_{j2}(s)$ and $\mathcal{D}_n$ via the posterior distribution of random effects $\bmath{b}_j$ and posterior distribution of the vector of all parameters $\bmath{\theta}$, respectively.

Using principles from statistical decision theory in a Bayesian setting \citep{bergerDecisionTheory,robertBayesianChoice}, we find the time $u$ of the next biopsy by minimizing the posterior expected loss $E_g\big\{L(T^*_j, u)\big\}$, where the expectation is taken with respect to $g(T^*_j)$.
\begin{equation*}
E_g\big\{L(T^*_j, u)\big\} = \int_t^\infty L(T^*_j, u) p\big\{T^*_j \mid T^*_j > t, \mathcal{Y}_j(s), \mathcal{D}_n\big\} \rmn{d} T^*_j.
\end{equation*}
In this work, we selected three loss functions from the literature \citep{robertBayesianChoice}, the first two of which are squared loss and absolute loss. These are natural choices, since they penalize overshooting and undershooting the true GR $T^*_j$ equally (neither is preferred) and they have well known solutions available. The posterior expected losses are given by:

\begin{eqnarray*}
\left \{
\begin{array}{l}
\mbox{Squared Loss: } E_g\big\{(T^*_j - u)^2\big\}=E_g\big\{(T^*_j)^2\big\} + u^2 -2uE_g(T^*_j),\\
\mbox{Absolute Loss: } E_g\big(\left|{T^*_j - u}\right|\big)= \int_u^\infty (T^*_j - u) g(T^*_j)\rmn{d} T^*_j + \int_t^u (u - T^*_j) g(T^*_j)\rmn{d} T^*_j.\\
\end{array}
\right.
\end{eqnarray*}
The posterior expected losses attain their minimums at $u = E_g(T^*_j)$, that is, the expected time of GR, and $u=\mbox{median}_g(T^*_j)$, that is, the median time of GR. The latter can also be expressed as $\pi_j^{-1}(0.5 \mid t,s)$, where $\pi_j^{-1}(\cdot)$ is the inverse of dynamic survival probability $\pi_j(u \mid t, s) =\mbox{Pr}\big\{T^*_j \geq u \mid  T^*_j >t, \mathcal{Y}_j(s), D_n\big\}$, $u \geq t$ of patient $j$ \citep{rizopoulos2011dynamic}. 

Even though $E_g(T^*_j)$ or $\mbox{median}_g(T^*_j)$ may be obvious choices from a statistical perspective, from the viewpoint of doctors or patients, it could be more intuitive to make the decision for the next biopsy by placing a cutoff $1 - \kappa$, where $0 \leq \kappa \leq 1$, on the dynamic incidence/risk of GR. This approach would be successful if $\kappa$ can sufficiently well differentiate between patients who will obtain GR in a given period of time versus others. This approach is also useful when patients are apprehensive about delaying biopsies beyond a certain risk cutoff. Thus, a biopsy can be scheduled at a time point $u$ such that the dynamic risk of GR is higher than a certain threshold $1 - \kappa,\ $ beyond $u$. To this end, the posterior expected loss for the following multilinear loss function can be minimized to find the optimal $u$:
\begin{equation*}
\label{eq : loss_dynamic_risk}
L_{k_1, k_2}(T^*_j, u) =
    \begin{cases}
      k_2(T^*_j-u), k_2>0 & \text{if } T^*_j > u,\\
      k_1(u-T^*_j), k_1>0 & \text{otherwise},
    \end{cases}       
\end{equation*}
where $k_1, k_2$ are constants parameterizing the loss function. The posterior expected loss $E_g\big\{L_{k_1, k_2}(T^*_j, u)\big\}$ obtains its minimum at $u = \pi_j^{-1}\big\{k_1/{(k_1 + k_2)} \mid t,s \big\}$ \citep{robertBayesianChoice}. The choice of the two constants $k_1$ and $k_2$ is equivalent to the choice of $\kappa = {k_1}/{(k_1 + k_2)}$. To our knowledge, existing work on the choice of such risk thresholds in the context of prostate cancer is not available. Hence, we use multiple fixed thresholds (ranging from 5\% risk to 20\% risk)  suggested by the experts from the PRIAS program. However, given the time dependent nature of the problem thresholds should vary over time. To this end, we propose to choose a $\kappa$ for which a binary classification accuracy measure \citep{lopez2014optimalcutpoints}, discriminating between cases (patients who experience GR) and controls, is maximized. In joint models, a patient $j$ is predicted to be a case in the time window $\Delta t$ if $\pi_j(t + \Delta t \mid t,s) \leq \kappa$, or a control if $\pi_j(t + \Delta t \mid t,s) > \kappa$ \citep*{rizopoulosJMbayes, landmarking2017}.

As for the choice of the binary classification accuracy measure, we chose $\mbox{F}_1$ score since it is in line with our goal to focus on potential cases in time window $\Delta t$. The $\mbox{F}_1$ score combines both sensitivity and positive predictive value (PPV) and is defined as:
\begin{align*}
\mbox{F}_1(t, \Delta t, s, \kappa) &= 2\frac{\mbox{TPR}(t, \Delta t, s, \kappa)\ \mbox{PPV}(t, \Delta t, s, \kappa)}{\mbox{TPR}(t, \Delta t, s, \kappa) + \mbox{PPV}(t, \Delta t, s, \kappa)},\\
\mbox{TPR}(t, \Delta t, s, \kappa) &= \mbox{Pr}\big\{\pi_j(t + \Delta t \mid t,s) \leq \kappa \mid t < T^*_j \leq t + \Delta t\big\},\\
\mbox{PPV}(t, \Delta t, s, \kappa) &= \mbox{Pr}\big\{t < T^*_j \leq t + \Delta t \mid \pi_j(t + \Delta t \mid t,s) \leq \kappa \big\},
\end{align*}
where $\mbox{TPR}(\cdot)$ and $\mbox{PPV}(\cdot)$ denote time dependent true positive rate (sensitivity) and positive predictive value (precision), respectively. The estimation for both is similar to the estimation of $\mbox{AUC}(t, \Delta t, s)$ given by \citet{landmarking2017}. Since a high $\mbox{F}_1$ score is desired, the corresponding value of $\kappa$ is $\argmax_{\kappa} \mbox{F}_1(t, \Delta t, s, \kappa)$. We compute the latter using a grid search approach. That is, first the $\mbox{F}_1$ score is computed using the available dataset over a fine grid of $\kappa$ values between 0 and 1, and then $\kappa$ corresponding to the highest $\mbox{F}_1$ score is chosen. Furthermore, in this paper we use $\kappa$ chosen only on the basis of the $\mbox{F}_1$ score.




In practice, for some patients, we may not have sufficient information to accurately estimate their PSA profile. The resulting high variance of $g(T^*_j)$ could lead to a mean (or median) time of GR which overshoots the true $T_j^*$ by a big margin. In such cases, the approach based on the dynamic risk of GR with smaller risk thresholds is more risk-averse and thus could be more robust to large overshooting margins. This consideration leads us to a hybrid approach, namely, to select $u$ using dynamic risk of GR based approach when the spread of $g(T_j^*)$ is large, while using $E_g(T^*_j)$ or $\mbox{median}_g(T^*_j)$ when the spread of $g(T_j^*)$ is small. What constitutes a large spread will be application-specific. In PRIAS, within the first 10 years, the maximum possible delay in detection of GR is three years. Thus we propose that if the difference between the 0.025 quantile of $g(T^*_j)$, and $E_g(T^*_j)$ or $\mbox{median}_g(T^*_j)$ is more than three years then proposals based on the dynamic risk of GR be used instead.

